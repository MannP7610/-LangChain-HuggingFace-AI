# -*- coding: utf-8 -*-
"""(LangChain/HuggingFace)AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jpAkrTOjxO57aRBhXUqoRJSRmxwWK5Ov
"""

!pip install langchain openai langchain-openai

!pip install langchain-community

!pip install langchain huggingface_hub

!pip install gradio

import os
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "your_huggingface_api_token"

import os
import subprocess
import tempfile
import gradio as gr
from langchain.llms import HuggingFaceHub

huggingface_api_token = "your_huggingface_api_token"

def generate_code(prompt: str) -> str:
    """Generates Python code based on the user prompt using a HuggingFace model."""
    llm = HuggingFaceHub(
        repo_id="bigcode/starcoder",
        model_kwargs={"temperature": 0.1},
    )
    response = llm.invoke(prompt)

    extracted_code = ""
    if "```python" in response:
        extracted_code = response.split("```python\n")[-1].split("```")[0]
    elif "```" in response:
        extracted_code = response.split("```\n")[-1].split("```")[0]
    else:
        extracted_code = response.strip()

    if "def " not in extracted_code:
        return "Error: The model did not generate valid Python code."

    return extracted_code.strip()

def execute_code(code: str) -> str:
    """Executes Python code safely in a temporary file."""
    with tempfile.NamedTemporaryFile(suffix=".py", delete=False) as temp_file:
        temp_file.write(code.encode("utf-8"))
        temp_file_path = temp_file.name

    try:
        result = subprocess.run(["python", temp_file_path], capture_output=True, text=True, timeout=10)
        return result.stdout if result.stdout else result.stderr
    except Exception as e:
        return str(e)

def code_generation_interface(prompt: str):
    """Handles the UI interaction for generating and executing code."""
    code = generate_code(prompt)
    execution_output = execute_code(code)
    return code, execution_output

iface = gr.Interface(
    fn=code_generation_interface,
    inputs=gr.Textbox(lines=2, placeholder="Enter your coding prompt here..."),
    outputs=[gr.Code(), gr.Textbox(label="Execution Output")],
    title="Code Generator & Executor",
    description="Enter a prompt to generate and execute Python code using Hugging Face models."
)

iface.launch()